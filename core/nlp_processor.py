import re
from typing import Dict, List, Tuple
from datetime import datetime
import random

from functools import lru_cache

class NLPProcessor:
    def __init__(self):
        # Cache cho c√°c k·∫øt qu·∫£ ph√¢n t√≠ch
        self._cache = {}
        self._cache_size = 1000
        
        # T·ª´ kh√≥a theo ch·ªß ƒë·ªÅ
        self.topic_keywords = {
            'greeting': ['ch√†o', 'hi', 'hello', 'hey', 'good'],
            'price': ['gi√°', 'price', 'cost', 'bao nhi√™u', 'ƒë·∫Øt', 'r·∫ª'],
            'order': ['ƒë·∫∑t', 'mua', 'order', 'book', 'ƒë∆°n h√†ng'],
            'status': ['tr·∫°ng th√°i', 't√¨nh tr·∫°ng', 'status', 'ki·ªÉm tra'],
            'help': ['gi√∫p', 'help', 'h∆∞·ªõng d·∫´n', 'guide', 'support'],
            'game': ['war thunder', 'game', 'tank', 'plane', 'xe tƒÉng', 'm√°y bay'],
            'time': ['khi n√†o', 'bao l√¢u', 'th·ªùi gian', 'deadline', 'h·∫°n'],
            'payment': ['thanh to√°n', 'payment', 'chuy·ªÉn kho·∫£n', 'ti·ªÅn'],
        }

        # Ng·ªØ c·∫£nh c·∫£m x√∫c
        self.emotion_keywords = {
            'positive': ['vui', 't·ªët', 'th√≠ch', 'hay', 'ƒë∆∞·ª£c', 'ok', 'oke', 'yes', 'th·∫ø', 'ƒë√∫ng'],
            'negative': ['bu·ªìn', 'kh√¥ng', 'ch∆∞a', 'sai', 'l·ªói', 'kh√≥', 'v·∫•n ƒë·ªÅ'],
            'urgent': ['g·∫•p', 'nhanh', 'urgent', 's·ªõm', 'c√†ng s·ªõm c√†ng t·ªët'],
            'confused': ['sao', 'l√†m sao', 'th·∫ø n√†o', 'nh∆∞ n√†o', 'kh√¥ng hi·ªÉu', 'kh√≥ hi·ªÉu'],
        }

        # Context l·ªãch s·ª≠
        self.conversation_history = []
        self.max_history = 5

    @lru_cache(maxsize=1000)
    def analyze_intent(self, text: str) -> Dict[str, float]:
        """Ph√¢n t√≠ch √Ω ƒë·ªãnh c·ªßa c√¢u h·ªèi v·ªõi cache v√† context"""
        text = text.lower()
        scores = {}
        
        # L·∫•y top 3 intent c√≥ ƒëi·ªÉm cao nh·∫•t ƒë·ªÉ tr√°nh l·∫∑p l·∫°i
        top_intents = []
        
        # T√≠nh ƒëi·ªÉm cho t·ª´ng ch·ªß ƒë·ªÅ v√† l∆∞u top 3
        for topic, keywords in self.topic_keywords.items():
            score = sum(1.0 for word in keywords if word in text)
            if score > 0:
                score = score / len(text.split())
                scores[topic] = score
                top_intents.append((topic, score))
        
        # S·∫Øp x·∫øp v√† ch·ªâ gi·ªØ l·∫°i top intent c√≥ ƒëi·ªÉm cao nh·∫•t
        if top_intents:
            top_intents.sort(key=lambda x: x[1], reverse=True)
            top_intent = top_intents[0]
            scores = {top_intent[0]: top_intent[1]}

        # Ph√¢n t√≠ch c·∫£m x√∫c
        for emotion, keywords in self.emotion_keywords.items():
            score = sum(1.0 for word in keywords if word in text)
            if score > 0:
                scores[f"emotion_{emotion}"] = score / len(text.split())

        return scores

    def generate_contextual_response(self, 
                                   text: str, 
                                   base_response: str, 
                                   context: Dict) -> str:
        """T·∫°o c√¢u tr·∫£ l·ªùi c√≥ ng·ªØ c·∫£nh"""
        intent_scores = self.analyze_intent(text)
        
        # Th√™m v√†o l·ªãch s·ª≠
        self.conversation_history.append({
            'text': text,
            'intent': intent_scores,
            'timestamp': datetime.now().isoformat()
        })
        if len(self.conversation_history) > self.max_history:
            self.conversation_history.pop(0)

        # ƒêi·ªÅu ch·ªânh c√¢u tr·∫£ l·ªùi d·ª±a tr√™n ng·ªØ c·∫£nh
        response = base_response

        # X·ª≠ l√Ω c·∫£m x√∫c
        if 'emotion_positive' in intent_scores:
            response = self._add_positive_tone(response)
        elif 'emotion_negative' in intent_scores:
            response = self._add_empathy(response)
        elif 'emotion_urgent' in intent_scores:
            response = self._add_urgency(response)
        elif 'emotion_confused' in intent_scores:
            response = self._add_explanation(response)

        # Th√™m ng·ªØ c·∫£nh th·ªùi gian
        hour = datetime.now().hour
        if 5 <= hour < 12:
            response = self._add_time_context(response, "morning")
        elif 12 <= hour < 18:
            response = self._add_time_context(response, "afternoon")
        else:
            response = self._add_time_context(response, "evening")

        # Th√™m t√≠nh li√™n t·ª•c n·∫øu c√≥ l·ªãch s·ª≠
        if len(self.conversation_history) > 1:
            response = self._add_conversation_continuity(response)

        return response

    def _add_positive_tone(self, text: str) -> str:
        """Th√™m gi·ªçng ƒëi·ªáu t√≠ch c·ª±c"""
        positive_additions = [
            "R·∫•t vui khi ",
            "Tuy·ªát v·ªùi! ",
            "Th·∫≠t t·ªët! ",
            "T√¥i r·∫•t vui ",
        ]
        return random.choice(positive_additions) + text

    def _add_empathy(self, text: str) -> str:
        """Th√™m s·ª± ƒë·ªìng c·∫£m"""
        empathy_additions = [
            "T√¥i hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n. ",
            "ƒê·ª´ng lo l·∫Øng! ",
            "ƒê·ªÉ t√¥i gi√∫p b·∫°n nh√©. ",
            "T√¥i s·∫Ω c·ªë g·∫Øng gi√∫p b·∫°n. ",
        ]
        return random.choice(empathy_additions) + text

    def _add_urgency(self, text: str) -> str:
        """Th√™m t√≠nh kh·∫©n c·∫•p"""
        urgency_additions = [
            "T√¥i s·∫Ω x·ª≠ l√Ω ngay cho b·∫°n. ",
            "ƒê·ªÉ t√¥i ∆∞u ti√™n gi√∫p b·∫°n. ",
            "S·∫Ω x·ª≠ l√Ω g·∫•p cho b·∫°n. ",
            "T√¥i s·∫Ω l√†m nhanh nh·∫•t c√≥ th·ªÉ. ",
        ]
        return random.choice(urgency_additions) + text

    def _add_explanation(self, text: str) -> str:
        """Th√™m gi·∫£i th√≠ch chi ti·∫øt"""
        explanation_additions = [
            "ƒê·ªÉ t√¥i gi·∫£i th√≠ch r√µ h∆°n: ",
            "T√¥i s·∫Ω gi·∫£i th√≠ch chi ti·∫øt nh√©. ",
            "B·∫°n c√≥ th·ªÉ hi·ªÉu ƒë∆°n gi·∫£n l√†: ",
            "N√≥i m·ªôt c√°ch d·ªÖ hi·ªÉu th√¨: ",
        ]
        return random.choice(explanation_additions) + text

    def _add_time_context(self, text: str, time_of_day: str) -> str:
        """Th√™m ng·ªØ c·∫£nh th·ªùi gian"""
        if "ch√†o" not in text.lower():
            return text
            
        time_additions = {
            "morning": ["bu·ªïi s√°ng", "‚òÄÔ∏è"],
            "afternoon": ["bu·ªïi chi·ªÅu", "üå§Ô∏è"],
            "evening": ["bu·ªïi t·ªëi", "üåô"]
        }
        addition = time_additions.get(time_of_day, [""])[0]
        emoji = time_additions.get(time_of_day, [""])[1]
        return f"Ch√†o {addition}! {emoji} " + text.replace("Ch√†o", "", 1).strip()

    def _add_conversation_continuity(self, text: str) -> str:
        """Th√™m t√≠nh li√™n t·ª•c cho cu·ªôc tr√≤ chuy·ªán"""
        last_topic = None
        for history in reversed(self.conversation_history[:-1]):
            intent_scores = history['intent']
            if intent_scores:
                last_topic = max(intent_scores.items(), key=lambda x: x[1])[0]
                break

        if last_topic and last_topic in self.topic_keywords:
            continuity_phrases = [
                f"Ti·∫øp theo v·ªÅ {last_topic}, ",
                f"Ngo√†i ra, ",
                f"Th√™m n·ªØa, ",
                f"N√≥i th√™m v·ªÅ v·∫•n ƒë·ªÅ n√†y, ",
            ]
            return random.choice(continuity_phrases) + text

        return text

    # === Methods required for ai_handler.py integration ===
    def analyze(self, text: str):
        """Return (intent, entities) tuple."""
        intent_scores = self.analyze_intent(text)
        # Pick the highest scoring intent as main intent
        intent = None
        max_score = 0
        for k, v in intent_scores.items():
            if not k.startswith('emotion_') and v > max_score:
                intent = k
                max_score = v
        # Simple entity extraction: return keywords found
        entities = [word for topic in self.topic_keywords.values() for word in topic if word in text.lower()]
        return intent, entities

    def detect_emotion(self, text: str):
        """Detect emotion from text using emotion_keywords."""
        text = text.lower()
        for emotion, keywords in self.emotion_keywords.items():
            for word in keywords:
                if word in text:
                    return emotion
        return None

    @lru_cache(maxsize=1000)
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """Rudimentary similarity: Jaccard index of word sets with cache."""
        # Convert to frozen sets for hashability in cache
        set1 = frozenset(text1.lower().split())
        set2 = frozenset(text2.lower().split())
        if not set1 or not set2:
            return 0.0
        return len(set1 & set2) / len(set1 | set2)

    def compare_entities(self, entities1, entities2) -> float:
        """Return ratio of shared entities."""
        if not entities1 or not entities2:
            return 0.0
        set1 = set(entities1)
        set2 = set(entities2)
        return len(set1 & set2) / max(len(set1 | set2), 1)

    def adjust_response_tone(self, response: str, emotion: str) -> str:
        """Adjust response tone based on emotion."""
        if emotion == 'positive':
            return self._add_positive_tone(response)
        elif emotion == 'negative':
            return self._add_empathy(response)
        elif emotion == 'urgent':
            return self._add_urgency(response)
        elif emotion == 'confused':
            return self._add_explanation(response)
        return response

    def generate_response(self, input_text: str, intent, entities, emotion=None):
        """Generate a smart contextual response."""
        # C√°c m·∫´u c√¢u tr·∫£ l·ªùi theo intent
        intent_responses = {
            'greeting': [
                "Xin ch√†o! M√¨nh c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?",
                "Hey! B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?",
                "Ch√†o b·∫°n! M√¨nh ƒëang l·∫Øng nghe n√®"
            ],
            'price': [
                "ƒê·ªÉ xem gi√° ch√≠nh x√°c, b·∫°n d√πng l·ªánh /tinhgia nh√©!",
                "M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n t√≠nh gi√°. B·∫°n c·∫ßn b√°o gi√° cho d·ªãch v·ª• n√†o?",
                "B·∫°n mu·ªën xem b√°o gi√° cho d·ªãch v·ª• n√†o?"
            ],
            'order': [
                "ƒê·ªÉ ƒë·∫∑t ƒë∆°n, b·∫°n d√πng l·ªánh /donhang nh√©!",
                "M√¨nh s·∫Ω h∆∞·ªõng d·∫´n b·∫°n quy tr√¨nh ƒë·∫∑t ƒë∆°n",
                "B·∫°n mu·ªën ƒë·∫∑t ƒë∆°n? M√¨nh s·∫Ω gi√∫p b·∫°n!"
            ],
            'status': [
                "Ki·ªÉm tra tr·∫°ng th√°i ƒë∆°n b·∫±ng l·ªánh /trangthai nh√©!",
                "B·∫°n c·∫ßn m√£ ƒë∆°n ƒë·ªÉ ki·ªÉm tra tr·∫°ng th√°i",
                "M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n xem tr·∫°ng th√°i ƒë∆°n"
            ],
            'help': [
                "B·∫°n c·∫ßn gi√∫p ƒë·ª° g√¨? M√¨nh lu√¥n s·∫µn s√†ng!",
                "M√¨nh c√≥ th·ªÉ gi·∫£i ƒë√°p th·∫Øc m·∫Øc cho b·∫°n",
                "H√£y cho m√¨nh bi·∫øt b·∫°n c·∫ßn h·ªó tr·ª£ g√¨ nh√©"
            ],
            'game': [
                "B·∫°n quan t√¢m ƒë·∫øn ph·∫ßn n√†o c·ªßa game?",
                "M√¨nh c√≥ th·ªÉ t∆∞ v·∫•n v·ªÅ c√°c t√≠nh nƒÉng trong game",
                "C·∫ßn th√¥ng tin g√¨ v·ªÅ game, b·∫°n c·ª© h·ªèi nh√©!"
            ],
            'payment': [
                "Th√¥ng tin thanh to√°n s·∫Ω ƒë∆∞·ª£c g·ª≠i sau khi ƒë∆°n ƒë∆∞·ª£c duy·ªát",
                "B·∫°n s·∫Ω nh·∫≠n h∆∞·ªõng d·∫´n thanh to√°n qua DM",
                "M·ªçi giao d·ªãch ƒë·ªÅu ƒë∆∞·ª£c b·∫£o ƒë·∫£m an to√†n"
            ]
        }

        # Ch·ªçn response d·ª±a tr√™n intent v√† context
        if intent and intent in intent_responses:
            base = random.choice(intent_responses[intent])
        else:
            # Fallback responses th√¥ng minh h∆°n
            fallbacks = [
                "M√¨nh hi·ªÉu b·∫°n ƒëang c·∫ßn h·ªó tr·ª£. B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n ƒë∆∞·ª£c kh√¥ng?",
                "B·∫°n c·∫ßn t√¨m hi·ªÉu th√™m v·ªÅ v·∫•n ƒë·ªÅ g√¨?",
                "M√¨nh mu·ªën hi·ªÉu r√µ h∆°n nhu c·∫ßu c·ªßa b·∫°n",
                "B·∫°n c√≥ th·ªÉ chia s·∫ª th√™m kh√¥ng? M√¨nh s·∫Ω c·ªë g·∫Øng gi√∫p b·∫°n"
            ]
            base = random.choice(fallbacks)

        # Th√™m th√¥ng tin h·ªØu √≠ch n·∫øu ph√°t hi·ªán entities quan tr·ªçng
        if entities:
            useful_info = {
                'sl': " (Tip: 1M SL = 100k VNƒê)",
                'rp': " (Tip: Premium RP c√≥ gi√° t·ªët h∆°n)",
                'module': " (Tip: C√≥ nhi·ªÅu lo·∫°i module kh√°c nhau)",
                'event': " (Tip: Th·ªùi gian event c√≥ h·∫°n)"
            }
            for entity in entities:
                if entity.lower() in useful_info:
                    base += useful_info[entity.lower()]

        # ƒêi·ªÅu ch·ªânh gi·ªçng ƒëi·ªáu d·ª±a tr√™n emotion
        if emotion:
            base = self.adjust_response_tone(base, emotion)

        return base.strip()

    def update_model(self, input_text, output_text, intent, entities):
        """Stub for model update (no-op for now)."""
        pass
